# ğŸ•¸ï¸ Web Scraping

## ğŸ¯ Video Hedefleri ve GiriÅŸ

Bu videoda **Web Scraping** konusunu ele alacaÄŸÄ±z.

Bu videoyu izledikten sonra:

* *web scraping* tanÄ±mlayabilecek,
* `BeautifulSoup` nesnelerinin rolÃ¼nÃ¼ anlayabilecek,
* `find_all` metodunu uygulayabilecek
* ve bir web sitesini *web scrape* edebileceksiniz.

Bir spor takÄ±mÄ±nÄ±n en iyi oyuncularÄ±nÄ± bulmak iÃ§in yÃ¼zlerce veri noktasÄ±nÄ± analiz etmek isteseydiniz ne yapardÄ±nÄ±z?

FarklÄ± web sitelerinden bilgileri tek tek kopyalayÄ±p bir **e-tabloya** mÄ± yapÄ±ÅŸtÄ±rÄ±rdÄ±nÄ±z?

DoÄŸru veriyi bulmak iÃ§in saatler harcayÄ±p, sonunda gÃ¶rev Ã§ok bunaltÄ±cÄ± olduÄŸu iÃ§in vaz mÄ± geÃ§erdiniz?

Ä°ÅŸte burada **web scraping** yardÄ±mcÄ± olabilir.

Web scraping, bir web sitesinden bilgileri otomatik olarak Ã§Ä±karmak iÃ§in kullanÄ±labilen bir sÃ¼reÃ§tir ve saatler deÄŸil, birkaÃ§ dakika iÃ§inde kolayca gerÃ§ekleÅŸtirilebilir.

BaÅŸlamak iÃ§in sadece biraz Python koduna ve **Requests** ile **Beautiful Soup** adÄ±nda iki modÃ¼lÃ¼n yardÄ±mÄ±na ihtiyacÄ±mÄ±z var.

---

## ğŸ€ Ulusal Basketbol Ligi Ã–rneÄŸi ve BeautifulSoup Nesnesi

Diyelim ki sizden, aÅŸaÄŸÄ±daki web sayfasÄ±ndan **Ulusal Basketbol Ligi** oyuncularÄ±nÄ±n adÄ±nÄ± ve maaÅŸÄ±nÄ± bulmanÄ±z istendi.

Ã–nce `BeautifulSoup`â€™u iÃ§e aktarÄ±rÄ±z.

Web sayfasÄ±nÄ±n HTMLâ€™ini, `HTML` adlÄ± deÄŸiÅŸkende bir **string** olarak saklayabiliriz.

Bir dokÃ¼manÄ± *parse* etmek iÃ§in, onu `BeautifulSoup` kurucusuna ( *constructor* ) geÃ§iririz.

BÃ¶ylece, belgeyi iÃ§ iÃ§e geÃ§miÅŸ bir veri yapÄ±sÄ± olarak temsil eden `soup` adlÄ± `BeautifulSoup` nesnesini elde ederiz.

`BeautifulSoup`, HTMLâ€™i, HTMLâ€™i *parse* etmek iÃ§in kullanÄ±lan metotlara sahip, aÄŸaÃ§ benzeri ( *Tree-like* ) nesneler kÃ¼mesi olarak temsil eder.

OluÅŸturduÄŸumuz `soup` adlÄ± `BeautifulSoup` nesnesini kullanarak `BeautifulSoup` nesnesini gÃ¶zden geÃ§ireceÄŸiz.

---

## ğŸ·ï¸ Tag Nesnesi ve AÄŸaÃ§ (Tree) Temsili

`tag` nesnesi, orijinal belgedeki bir HTML etiketine karÅŸÄ±lÄ±k gelir.

Ã–rneÄŸin, `"title"` etiketi.

`h3` etiketini ele alalÄ±m.

AynÄ± ada sahip birden fazla `tag` varsa, bu etikete sahip ilk Ã¶ÄŸe seÃ§ilir.

Bu durumda, **Lebron James** iÃ§in, ismin `"b"` (bold) niteliÄŸi iÃ§inde yer aldÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼rÃ¼z.

Bunu Ã§Ä±karmak iÃ§in **aÄŸaÃ§ (Tree) temsili**ni kullanÄ±rÄ±z.

Haydi aÄŸaÃ§ temsilini kullanalÄ±m.

---

## ğŸŒ¿ AÄŸaÃ§ta Gezinme: child, parent ve sibling

`tag-object` deÄŸiÅŸkeni burada yer alÄ±r.

Etiketin *child* (Ã§ocuk) Ã¶ÄŸesine eriÅŸebilir veya dal boyunca aÅŸaÄŸÄ± doÄŸru ÅŸu ÅŸekilde ilerleyebilirsiniz:

AÄŸaÃ§ta yukarÄ± doÄŸru gezinmek iÃ§in `parent` niteliÄŸini kullanabilirsiniz.

`tag child` deÄŸiÅŸkeni burada yer alÄ±r.

`parent`â€™a eriÅŸebiliriz.

Bu, orijinal `tag` nesnesidir.

`"tag object"`in *sibling* (kardeÅŸ) Ã¶ÄŸesini bulabiliriz.

Bunun iÃ§in sadece `next-sibling` niteliÄŸini kullanÄ±rÄ±z.

---

## ğŸ§¬ Ã–zellikler, Navigable String ve `find_all` Metodu

Birinci kardeÅŸin ( *sibling one* ) kardeÅŸini bulabiliriz.

Yine `next sibling` niteliÄŸini kullanÄ±rÄ±z.

`tag child` nesnesini ele alalÄ±m.

Ã–zelliÄŸin adÄ±nÄ± ( *name* ) ve deÄŸerini ( *value* ), bir sÃ¶zlÃ¼kte anahtarâ€“deÄŸer Ã§ifti olarak ÅŸu ÅŸekilde eriÅŸebilirsiniz.

Ä°Ã§eriÄŸi, bir **Navigable string** olarak dÃ¶ndÃ¼rebilirsiniz; bu, `BeautifulSoup` iÅŸlevselliÄŸini destekleyen bir Python stringâ€™ine benzer.

Åimdi `find_all` metodunu gÃ¶zden geÃ§irelim.

Bu bir filtredir; bir etiketin adÄ±nÄ±, Ã¶zelliklerini, bir stringâ€™in metnini veya bunlarÄ±n bazÄ± kombinasyonlarÄ±nÄ± temel alarak filtreleme yapmak iÃ§in filtreleri kullanabilirsiniz.

---

## ğŸ• Pizza Listesi Ã–rneÄŸi ve SatÄ±r/SÃ¼tunlara EriÅŸim

Pizza yerlerinin listesini ele alalÄ±m.

Daha Ã¶nce olduÄŸu gibi bir `BeautifulSoup` nesnesi oluÅŸturun.

Ancak bu sefer, ona `table` adÄ±nÄ± verin.

`find_all()` metodu bir etiketin alt Ã¶ÄŸeleri (descendants) arasÄ±nda gezinir ve filtrelerinize uyan tÃ¼m alt Ã¶ÄŸeleri getirir.

Bunu, `table` Ã¼zerinde `tr` etiketi ile uygulayÄ±n.

SonuÃ§, bir listeye Ã§ok benzeyen Python  *iterable* â€™Ä±dÄ±r; her Ã¶ÄŸe, `tr` iÃ§in bir `tag` nesnesidir.

Bu, listedeki her bir satÄ±ra karÅŸÄ±lÄ±k gelir â€“ **tablo baÅŸlÄ±ÄŸÄ±** dahil.

Her Ã¶ÄŸe bir `tag` nesnesidir.

Ä°lk satÄ±rÄ± ele alalÄ±m.

Ã–rneÄŸin, ilk tablo hÃ¼cresini Ã§Ä±karabiliriz.

AyrÄ±ca her tablo hÃ¼cresini dolaÅŸabiliriz.

Ã–nce, `"table rows"` listesini, `row` deÄŸiÅŸkeni aracÄ±lÄ±ÄŸÄ±yla dolaÅŸÄ±rÄ±z.

Her Ã¶ÄŸe tablodaki bir satÄ±ra karÅŸÄ±lÄ±k gelir.

TÃ¼m tablo hÃ¼crelerini bulmak iÃ§in `find_all` metodunu uygulayabilir, ardÄ±ndan her satÄ±r iÃ§in `cells` deÄŸiÅŸkeni Ã¼zerinden yineleme yapabiliriz.

Her yinelemede, `cell` deÄŸiÅŸkeni, ilgili satÄ±r iÃ§in tablodaki bir Ã¶ÄŸeye karÅŸÄ±lÄ±k gelir.

Her bir Ã¶ÄŸe Ã¼zerinde yinelemeye devam eder ve bu iÅŸlemi her satÄ±r iÃ§in tekrarlarÄ±z.

---

## ğŸŒ Requests ile Bir Web SayfasÄ±nÄ± Scrape Etme

Åimdi `BeautifulSoup`â€™u bir web sayfasÄ±na nasÄ±l uygulayacaÄŸÄ±mÄ±zÄ± gÃ¶relim.

Bir web sayfasÄ±nÄ± *scrape* etmek iÃ§in ayrÄ±ca `Requests` kÃ¼tÃ¼phanesine de ihtiyaÃ§ duyarÄ±z.

Ä°lk adÄ±m, ihtiyaÃ§ duyulan modÃ¼lleri iÃ§e aktarmaktÄ±r.

Web sayfasÄ±nÄ± indirmek iÃ§in `requests` kÃ¼tÃ¼phanesinden `get` metodunu kullanÄ±n.

Girdi, URLâ€™dir.

Metni almak iÃ§in `text` niteliÄŸini kullanÄ±n ve bunu `page` deÄŸiÅŸkenine atayÄ±n.

ArdÄ±ndan, `page` deÄŸiÅŸkeninden `soup` adlÄ± bir `BeautifulSoup` nesnesi oluÅŸturun.

Bu, HTML sayfasÄ±nÄ± *parse* etmenizi saÄŸlar.

ArtÄ±k sayfayÄ± *scrape* edebilirsiniz.

Daha fazlasÄ± iÃ§in laboratuvarlara ( *labs* ) gÃ¶z atÄ±n.
